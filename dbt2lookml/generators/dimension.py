"""LookML dimension generator module."""
import logging
import re
from typing import Any, Dict, List, Optional, Set, Tuple

from dbt2lookml.enums import (
    LookerDateTimeframes,
    LookerDateTimeTypes,
    LookerDateTypes,
    LookerScalarTypes,
    LookerTimeFrame,
    LookerTimeTimeframes,
)
from dbt2lookml.generators.utils import (
    get_array_element_looker_type,
    get_catalog_column_info,
    get_column_name,
    is_single_value_array,
    map_bigquery_to_looker,
    safe_name,
)
from dbt2lookml.models.column_collections import ColumnCollections
from dbt2lookml.models.dbt import DbtModel, DbtModelColumn
from dbt2lookml.models.looker import DbtMetaLookerDimension
from dbt2lookml.utils import camel_to_snake


class LookmlDimensionGenerator:
    """Lookml dimension generator."""

    def __init__(self, args):
        """Initialize the generator with CLI arguments."""
        self._cli_args = args
        self._custom_timeframes = getattr(args, 'timeframes', {})
        self._include_iso_fields = getattr(args, 'include_iso_fields', False)

    def _get_conflicting_timeframes(
        self,
        dimension_group: Dict[str, Any],
        existing_dimension_names: set,
        original_column_name: str = None,
    ) -> List[str]:
        """Get timeframes that would conflict with existing dimensions.
        Args:
            dimension_group: The dimension group to check
            existing_dimension_names: Set of existing dimension names
            original_column_name: Original column name before _date removal
        Returns:
            List of timeframes that would create conflicts
        """
        group_name = dimension_group.get("name")
        group_type = dimension_group.get("type")
        if not (group_name and group_type == "time"):
            return []
        # Determine if this is a date or time dimension group
        looker_type = "date" if dimension_group.get("datatype") == "date" else "time"
        # Use enum values for timeframes
        if looker_type == "date":
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
        elif looker_type == "time":
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
        else:
            return []
        # Find conflicting timeframes
        conflicting_timeframes = []
        for timeframe in timeframes:
            generated_name = f"{group_name}_{timeframe}"
            # Check for direct conflicts with the generated name
            if generated_name in existing_dimension_names:
                conflicting_timeframes.append(timeframe)
            # Special case: check if original column name would conflict with this timeframe
            elif (
                original_column_name
                and original_column_name in existing_dimension_names
                and original_column_name == generated_name
            ):
                # Only conflict if the original column name exactly matches what would be generated
                conflicting_timeframes.append(timeframe)
        return conflicting_timeframes


    def _comment_conflicting_dimensions(
        self, dimensions: List[Dict[str, Any]], dimension_groups: List[Dict[str, Any]], model_name: str = None
    ) -> List[Dict[str, Any]]:
        """Rename regular dimensions that conflict with dimension groups by adding '_conflict' suffix.
        Args:
            dimensions: List of regular dimensions to process
            dimension_groups: List of dimension groups to check against
        Returns:
            List of dimensions with conflicts renamed
        """
        # Build set of all dimension names that would be generated by dimension groups
        dimension_group_generated_names = set()
        dimension_group_base_names = set()
        
        for dim_group in dimension_groups:
            group_name = dim_group.get("name")
            group_type = dim_group.get("type")
            timeframes = dim_group.get("timeframes", [])
            
            # Add the base dimension group name
            dimension_group_base_names.add(group_name)
            
            # Add all timeframe variants
            for timeframe in timeframes:
                if not timeframe.startswith("#"):  # Skip commented timeframes
                    dimension_group_generated_names.add(f"{group_name}_{timeframe}")
        
        # Process regular dimensions and rename conflicts
        processed_dimensions = []
        for dimension in dimensions:
            dim_name = dimension.get("name")
            
            # Check for conflicts
            is_conflicting = (
                dim_name in dimension_group_generated_names or
                dim_name in dimension_group_base_names
            )
            
            if is_conflicting:
                # Rename the conflicting dimension by adding '_conflict' suffix
                original_name = dim_name
                new_name = f"{dim_name}_conflict"
                
                # Create a copy of the dimension with the new name
                renamed_dimension = dimension.copy()
                renamed_dimension["name"] = new_name
                
                # Make the dimension hidden, Add a comment 
                renamed_dimension["hidden"] = f"yes # Renamed from '{original_name}' due to conflict with dimension group with same name"
                
                processed_dimensions.append(renamed_dimension)
                
                if model_name:
                    logging.debug(f"Renamed conflicting dimension '{original_name}' to '{new_name}' in model '{model_name}'")
                else:
                    logging.debug(f"Renamed conflicting dimension '{original_name}' to '{new_name}'")
            else:
                #logging.debug(f'6. adding dimensions to process dimensions: {dimension}')
                processed_dimensions.append(dimension)
        
        return processed_dimensions
    

    def _clean_dimension_groups_for_output(self, dimension_groups: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove internal fields from dimension groups before LookML output.
        Args:
            dimension_groups: List of dimension groups to clean
        Returns:
            List of dimension groups with internal fields removed
        """
        cleaned_groups = []
        for dim_group in dimension_groups:
            cleaned_group = {}
            # Copy only valid LookML fields, excluding internal tracking fields
            for key, value in dim_group.items():
                if not key.startswith("_"):
                    cleaned_group[key] = value
            cleaned_groups.append(cleaned_group)
        return cleaned_groups

    def _format_label(self, name: Optional[str] = None, remove_date: bool = True) -> str:
        """Format a name into a human-readable label.
        Args:
            name: The name to format
            remove_date: Whether to remove '_date' from the name
        Returns:
            Formatted label string
        """
        if name is None:
            return ""
        
        # Remove date suffix if requested
        if remove_date:
            if name.endswith('Date'):
                name = name[:-4]
            elif name.endswith('_date'):
                name = name[:-5]
        
        # Convert CamelCase to snake_case first, then to readable format
        snake_case = camel_to_snake(name)
        return snake_case.replace("_", " ").title()

    def _apply_meta_looker_attributes(self, target_dict: Dict[str, Any], column: DbtModelColumn, attributes: List[str]) -> None:
        """Apply meta attributes from column to target dictionary if they exist.
        Args:
            target_dict: Dictionary to update with meta attributes
            column: Column containing meta attributes
            attributes: List of attribute names to apply
        """
        if column.meta and column.meta.looker and column.meta.looker.dimension is not None:
            for attr in attributes:
                value = getattr(column.meta.looker.dimension, attr, None)
                if value is not None:
                    if attr == "value_format_name":
                        meta_value = value.value
                    elif isinstance(value, bool):
                        meta_value = "yes" if value else "no"
                    else:
                        meta_value = value
                    target_dict[attr] = meta_value

    def _create_iso_field(self, field_type: str, column: DbtModelColumn, sql: str) -> Dict[str, Any]:
        """Create an ISO year or week field.
        Args:
            field_type: Type of ISO field (year or week)
            column: Column to create field from
            sql: SQL expression for the field
        Returns:
            Dictionary containing ISO field definition
        """
        label_type = field_type.replace("_of_year", "")
        field = {
            "name": f"{column.name}_iso_{field_type}",
            "label": f"{self._format_label(column.name)} ISO {label_type.title()}",
            "type": "number",
            "sql": f"Extract(iso{label_type} from {sql})",
            "description": f"iso year for {column.name}",
            "group_label": "D Date",
            "value_format_name": "id",
        }
        self._apply_meta_looker_attributes(field, column, ["group_label", "label"])
        if field_type == "week_of_year":
            field["label"] = field["label"].replace("Week", "Week Of Year")
        return field

    def _get_looker_type(self, column: DbtModelColumn) -> str:
        """Get the category of a column's type.
        Args:
            column: Column to get type for
        Returns:
            Type category (scalar, date, time)
        """
        looker_type = map_bigquery_to_looker(column.data_type)
        if looker_type in LookerDateTimeTypes.values():
            return "time"
        elif looker_type in LookerDateTypes.values():
            return "date"
        return "scalar"

    def create_dimension(self, column: DbtModelColumn, sql: str, model: DbtModel = None, is_hidden: bool = False, include_names: Optional[List[str]] = None) -> Optional[Dict[str, Any]]:
        """Create a basic dimension dictionary.
        Args:
            column: Column to create dimension from
            sql: SQL expression for the dimension
            model: DBT model for catalog lookups
            is_hidden: Whether the dimension is hidden
            include_names: List of included names for nested view context
        Returns:
            Dictionary containing dimension definition
        """
        data_type = map_bigquery_to_looker(column.data_type)
        if data_type is None:
            return None

        # Determine dimension name
        dimension_name = self._determine_dimension_name(column, include_names)
        
        # Create base dimension structure
        dimension = self._create_base_dimension(dimension_name, data_type, sql)
        
        # Add group labels for nested fields
        self._add_group_labels(dimension, column)
        
        # Apply visibility and special attributes
        self._apply_visibility_attributes(dimension, column, is_hidden)
        
        # Add description
        self._add_dimension_description(dimension, column, model)
        
        # Apply meta looker attributes
        self._apply_meta_looker_attributes(
            dimension,
            column,
            ["description", "group_label", "value_format_name", "label", "hidden"],
        )
        
        return dimension

    def _determine_dimension_name(self, column: DbtModelColumn, include_names: Optional[List[str]] = None) -> str:
        """Determine the appropriate dimension name based on column context.
        
        Args:
            column: Column to determine name for
            include_names: List of included names for nested view context
            
        Returns:
            Processed dimension name
        """
        # Start with base name based on nesting
        if column.nested:
            dimension_name = column.lookml_long_name
        else:
            dimension_name = column.lookml_name
        
        # Apply nested view naming conventions
        if include_names and any('.' in name for name in include_names):
            dimension_name = self._apply_nested_view_naming(dimension_name, include_names, column)
        else:
            dimension_name = self._apply_standard_naming(dimension_name, column)
            
        return dimension_name
    
    def _apply_nested_view_naming(self, dimension_name: str, include_names: List[str], column: DbtModelColumn) -> str:
        """Apply naming conventions for nested views to match fixture expectations.
        
        Args:
            dimension_name: Current dimension name
            include_names: List of included names
            column: Column being processed
            
        Returns:
            Processed dimension name for nested views
        """
        # Extract array model name from include_names (format: "array.model.name.dummy")
        array_model_from_include = include_names[0].rsplit('.', 1)[0]  # Remove ".dummy"
        
        logging.debug(f"Nested view dimension naming - Column: {column.name}")
        logging.debug(f"  Original dimension_name: {dimension_name}")
        logging.debug(f"  Array model from include: {array_model_from_include}")
        
        # The array model has N parts, so we need to strip the first N parts from lookml_long_name
        array_parts_count = len(array_model_from_include.split('.'))
        dimension_parts = dimension_name.split('__')
        
        logging.debug(f"  Array parts count: {array_parts_count}")
        logging.debug(f"  Dimension parts: {dimension_parts}")
        
        # Strip the first N parts that correspond to the array model
        if len(dimension_parts) > array_parts_count:
            stripped_parts = dimension_parts[array_parts_count:]
            dimension_name = '__'.join(stripped_parts)
            logging.debug(f"  After stripping {array_parts_count} prefix parts: {dimension_name}")
        elif '__' in dimension_name:
            # Fallback: strip the first prefix for backward compatibility
            original_name = dimension_name
            dimension_name = re.sub(r'^.*?__', '', dimension_name)
            logging.debug(f"  Fallback stripping first prefix: {original_name} -> {dimension_name}")
        
        logging.debug(f"  Final dimension name: {dimension_name}")
        return dimension_name
    
    def _apply_standard_naming(self, dimension_name: str, column: DbtModelColumn) -> str:
        """Apply standard naming conventions for non-nested views.
        
        Args:
            dimension_name: Current dimension name
            column: Column being processed
            
        Returns:
            Processed dimension name with camelCase conversion
        """
        # Use original_name if available to get the proper camelCase format
        source_name = getattr(column, 'original_name', column.name) or column.name
        
        if '.' in source_name:
            # Convert dots to double underscores: Classification.ItemGroup.Code -> classification__item_group__code
            parts = source_name.split('.')
            snake_parts = [camel_to_snake(part).lower() for part in parts]
            dimension_name = '__'.join(snake_parts)
        else:
            # Apply camelCase conversion for single names
            dimension_name = camel_to_snake(source_name).lower()
            
        return dimension_name
    
    def _create_base_dimension(self, dimension_name: str, data_type: str, sql: str) -> Dict[str, Any]:
        """Create the base dimension dictionary with name, type, and SQL.
        
        Args:
            dimension_name: Name for the dimension
            data_type: Looker data type
            sql: SQL expression
            
        Returns:
            Base dimension dictionary
        """
        dimension: Dict[str, Any] = {"name": safe_name(dimension_name)}
        
        # Add type for scalar types (should come before sql)
        if data_type in LookerScalarTypes.values():
            dimension["type"] = data_type
            
        dimension["sql"] = sql
        return dimension
    
    def _add_group_labels(self, dimension: Dict[str, Any], column: DbtModelColumn) -> None:
        """Add group labels for nested fields in main view.
        
        Args:
            dimension: Dimension dictionary to modify
            column: Column being processed
        """
        if column.nested and '.' in column.name:
            parts = column.name.split('.')
            if len(parts) >= 2:
                # Create dynamic group label from all parts except the last one
                group_parts = parts[:-1]
                group_label = self._create_group_label(group_parts)
                dimension["group_label"] = group_label

                # Add group item label from the last part
                # Use original_name if available to preserve CamelCase, otherwise fall back to name
                if column.original_name and '.' in column.original_name:
                    original_parts = column.original_name.split('.')
                    if len(original_parts) == len(parts):
                        last_part = original_parts[-1]
                    else:
                        last_part = parts[-1]
                else:
                    last_part = parts[-1]
                dimension["group_item_label"] = self._create_item_label(last_part)
    
    def _apply_visibility_attributes(self, dimension: Dict[str, Any], column: DbtModelColumn, is_hidden: bool) -> None:
        """Apply visibility and special attributes based on column properties.
        
        Args:
            dimension: Dimension dictionary to modify
            column: Column being processed
            is_hidden: Whether dimension should be hidden
        """
        # Add primary key attributes
        if column.is_primary_key:
            dimension["primary_key"] = "yes"
            dimension["hidden"] = "yes"
            dimension["value_format_name"] = "id"
        elif is_hidden:
            dimension["hidden"] = "yes"
        # Mark deeply nested struct fields as hidden (3+ levels of nesting)
        elif column.nested and len(column.name.split('.')) >= 3:
            dimension["hidden"] = "yes"
            
        # Handle array and struct types
        if "ARRAY" in f"{column.data_type}":
            dimension["hidden"] = "yes"
            dimension["tags"] = ["array"]
            dimension.pop("type", None)
        elif "STRUCT" in f"{column.data_type}":
            dimension["hidden"] = "yes"
            dimension["tags"] = ["struct"]
    
    def _add_dimension_description(self, dimension: Dict[str, Any], column: DbtModelColumn, model: DbtModel = None) -> None:
        """Add description to dimension from column or catalog.
        
        Args:
            dimension: Dimension dictionary to modify
            column: Column being processed
            model: DBT model for catalog lookups
        """
        description = self._get_dimension_description(column, model)
        if description:
            dimension["description"] = description

    def lookml_dimension_group(
        self, column: DbtModelColumn, looker_type: str, table_format_sql: bool, model: DbtModel, is_nested_view: bool = False, array_model_name: str = None
    ) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]], List[Dict[str, Any]]]:
        """Create dimension group for date/time fields.
        Args:
            column: Column to create dimension group from
            looker_type: Type of dimension group (date, time)
            table_format_sql: Whether to format SQL for table
            model: Model containing column
            is_nested_view: Whether this is for a nested view (affects naming)
            array_model_name: Name of array model for nested views (for prefix stripping)
        Returns:
            Tuple containing dimension group, dimension group set, and dimensions
        """
        if map_bigquery_to_looker(column.data_type) is None:
            return None, None, None
        if looker_type == "date":
            convert_tz = "no"
            # Use enum values for timeframes
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
            column_name_adjusted = self.transform_date_column_name(column, is_nested_view, array_model_name)
        elif looker_type == "time":
            convert_tz = "yes"
            # Use enum values for timeframes
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
            column_name_adjusted = self.transform_date_column_name(column, is_nested_view, array_model_name)
        else:
            return None, None, None
        sql = get_column_name(column, table_format_sql, getattr(model, '_catalog_data', None), model.unique_id, is_nested_view, array_model_name)
        dimensions = []
        # Use original_name for proper formatting if available, otherwise use column name
        label_source = getattr(column, 'original_name', column.name)
        
        # For nested fields, separate the label and group_label
        if '.' in label_source:
            parts = label_source.split('.')
            # Label is just the last part (field name)
            field_label = self._format_label(parts[-1], remove_date=False)
            # Group label is the parent parts
            group_parts = parts[:-1]
            group_label = self._create_group_label(group_parts)
        else:
            # For non-nested fields, label and group_label are the same
            field_label = self._format_label(label_source, remove_date=False)
            group_label = field_label
        
        dimension_group = {
            "name": safe_name(column_name_adjusted),
            "label": field_label,
            "type": 'time',
            "sql": sql,
            "datatype": map_bigquery_to_looker(column.data_type),
            "timeframes": timeframes,
            "group_label": ("D Date" if column_name_adjusted == "d" else group_label),
            "convert_tz": convert_tz,
            "_original_column_name": column.name,  # Store original column name for conflict detection
        }
        # Add description from column description or catalog comment
        description = self._get_dimension_description(column, model)
        if description:
            dimension_group["description"] = description
        self._apply_meta_looker_attributes(dimension_group, column, ["group_label", "label"])
        dimension_group_set = {
            "name": f"s_{column_name_adjusted}",
            "fields": [f"{column_name_adjusted}_{looker_time_timeframe}" for looker_time_timeframe in timeframes],
        }
        if looker_type == "date" and self._include_iso_fields:
            iso_year = self._create_iso_field("year", column, sql)
            iso_week_of_year = self._create_iso_field("week_of_year", column, sql)
            dimensions = [iso_year, iso_week_of_year]
            dimension_group_set["fields"].extend([f"{column.name}_iso_year", f"{column.name}_iso_week_of_year"])
        return dimension_group, dimension_group_set, dimensions

    def transform_date_column_name(self, column: DbtModelColumn, is_nested_view: bool = False, array_model_name: str = None) -> str:
        """Transform date column names to dimension group names.

        Removes 'Date' or 'date' suffix and converts to snake_case.
        Handles nested fields by processing each part separately.
        Only converts what can be reliably converted (CamelCase and nested fields).
        For nested views, strips the nested view prefix from dimension group names.

        Examples:
            DeliveryStartDate -> delivery_start (CamelCase conversion)
            deliverystartdate -> deliverystartdate (lowercase - keep as-is)
            format.period.EndDate -> format__period__end (nested fields)
            returnable_assets_deposit__returnable_asset_deposit_end -> returnable_asset_deposit_end (nested view)
        """

        column_name = column.original_name or column.name
        
        if '.' in column_name:
            result = self._process_nested_field(column_name, camel_to_snake)
        else:
            result = self._process_single_field(column_name, camel_to_snake)
        
        result = result.rstrip('_')
        
        if is_nested_view and array_model_name:
            result = self._strip_nested_view_prefix(result, array_model_name, column.name)
        
        return result

    def _process_nested_field(self, column_name: str, camel_to_snake_func) -> str:
        """Process nested field names (containing dots)."""
        parts = column_name.split('.')
        snake_parts = []
        
        for i, part in enumerate(parts):
            # Remove date suffix only from the last part
            if i == len(parts) - 1:
                part = self._remove_date_suffix(part)
            
            snake_parts.append(self._convert_part_to_snake(part, camel_to_snake_func))
        
        return '__'.join(snake_parts)

    def _process_single_field(self, column_name: str, camel_to_snake_func) -> str:
        """Process single field names (no dots)."""
        # Special case: exact "Date" or "date"
        if column_name.lower() == 'date':
            return 'date'
        
        base_name = self._remove_date_suffix(column_name).rstrip('_')
        return self._convert_part_to_snake(base_name, camel_to_snake_func)

    def _remove_date_suffix(self, part: str) -> str:
        """Remove various date suffixes from a string part."""
        if part.endswith('Date'):
            return part[:-4]
        elif part.endswith('_date'):
            return part[:-5]
        elif part.lower().endswith('date') and part != 'Date':
            return part[:-4]
        return part

    def _convert_part_to_snake(self, part: str, camel_to_snake_func) -> str:
        """Convert a part to snake_case if it's not pure lowercase."""
        if part.islower() and '_' not in part:
            # Pure lowercase - keep as-is
            return part
        else:
            # CamelCase or snake_case - convert
            return camel_to_snake_func(part)

    def _strip_nested_view_prefix(self, result: str, array_model_name: str, column_name: str) -> str:
        """Strip nested view prefix from dimension group names."""
        
        logging.debug(f"Dimension group naming - Column: {column_name}")
        logging.debug(f"  Original result: {result}")
        logging.debug(f"  Array model name: {array_model_name}")
        
        array_parts_count = len(array_model_name.split('.'))
        result_parts = result.split('__')
        
        logging.debug(f"  Array parts count: {array_parts_count}")
        logging.debug(f"  Result parts: {result_parts}")
        
        if len(result_parts) > array_parts_count:
            stripped_parts = result_parts[array_parts_count:]
            result = '__'.join(stripped_parts)
            logging.debug(f"  After stripping {array_parts_count} prefix parts: {result}")
        else:
            logging.debug(f"  Not enough parts to strip, keeping original: {result}")
        
        return result

    def _get_dimension_group_generated_names(self, column_name: str, looker_type: str) -> List[str]:
        """Get all dimension names that would be generated by a dimension group.
        Args:
            column_name: Base name of the column (with _date suffix removed)
            looker_type: Type of dimension group (date or time)
        Returns:
            List of dimension names that would be generated
        """
        if looker_type == "date":
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
        elif looker_type == "time":
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
        else:
            return []
        return [f"{column_name}_{timeframe}" for timeframe in timeframes]

    def _create_group_label(self, parts: list[str]) -> str:
        """Create a human-readable group label from nested field parts.

        Args:
            parts: List of field name parts (e.g., ['classification', 'assortment'])

        Returns:
            Formatted group label (e.g., 'Classification Assortment')
        """
        # Convert each part to title case, handling common patterns
        formatted_parts = []
        for part in parts:
            snake_case = camel_to_snake(part)
            # Use title() to properly capitalize each word
            title_case = snake_case.replace('_', ' ').title()
            formatted_parts.append(title_case)

        return ' '.join(formatted_parts)

    def _create_item_label(self, item: str) -> str:
        snake_case = camel_to_snake(item)
        return snake_case.replace('_', ' ').capitalize()

    def _get_dimension_description(self, column: DbtModelColumn, model: DbtModel) -> str:
        """Get description for dimension from column description or catalog comment.
        
        Args:
            column: Column to get description for
            model: Model containing the column
            
        Returns:
            Description string or None if no description available
        """
        # First try column description
        if column.description:
            return column.description
            
        # Then try catalog comment
        catalog_data = getattr(model, '_catalog_data', None)
        if catalog_data and 'nodes' in catalog_data and model.unique_id in catalog_data['nodes']:
            model_catalog = catalog_data['nodes'][model.unique_id]
            if 'columns' in model_catalog:
                # Look for column in catalog data (try both original case and lowercase)
                catalog_column = model_catalog['columns'].get(column.name)
                if not catalog_column:
                    # Try with original_name if available
                    original_name = getattr(column, 'original_name', None)
                    if original_name:
                        catalog_column = model_catalog['columns'].get(original_name)
                
                if catalog_column and catalog_column.get('comment'):
                    return catalog_column['comment']
                
        return None

    def _create_single_array_dimension(self, column: DbtModelColumn) -> Dict[str, Any]:
        """Create a dimension for a simple array type.
        Args:
            column: Column to create dimension from
        Returns:
            Dictionary containing dimension definition
        """
        data_type = map_bigquery_to_looker(column.inner_types[0])
        return {
            "name": column.lookml_name,
            "type": data_type,
            "sql": column.lookml_name,
            "description": column.description or "",
        }

    def _is_single_type_array(self, column: DbtModelColumn) -> bool:
        """Check if column is a simple array type.
        Args:
            column: Column to check
        Returns:
            Whether column is a simple array type
        """
        return column.data_type == "ARRAY" and (len(column.inner_types) == 1 and " " not in column.inner_types[0])

    def _add_dimension_to_dimension_group(self, model: DbtModel, dimensions: List[Dict[str, Any]], table_format_sql: bool = True):
        """Add dimensions to dimension groups.
        Args:
            model: Model containing dimensions
            dimensions: List of dimensions to add
            table_format_sql: Whether to format SQL for table
        """
        for column in model.columns.values():
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model, False, None)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)

    def lookml_dimensions_from_model(
        self,
        model: DbtModel,
        columns_subset: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from model using pre-filtered columns.
        Args:
            model: Model to generate dimensions from
            columns_subset: Pre-filtered columns to generate dimensions from
            is_nested_view: Whether this is for a nested view (affects naming)
            array_model_name: Name of array model for nested views (for naming)
        Returns:
            Tuple containing dimensions and nested dimensions
        """
        return self._generate_dimensions_from_columns(model, columns_subset, is_nested_view, array_model_name)

    def _generate_dimensions_from_columns(
        self,
        model: DbtModel,
        columns: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from a pre-filtered set of columns.
        
        This eliminates the need for include_names/exclude_names filtering.
        """
        dimensions: List[Dict[str, Any]] = []
        nested_dimensions: List[Dict[str, Any]] = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        
        # Add ISO date dimensions for main view only
        if not is_nested_view and self._include_iso_fields:
            self._add_dimension_to_dimension_group(model, dimensions, table_format_sql)
        
        # For nested views, we need to replicate the complex logic from the legacy approach
        if is_nested_view and array_model_name:
            # Find the array model column
            array_model_column = model.columns.get(array_model_name)
            return self._generate_nested_view_dimensions(model, columns, array_model_name, array_model_column)
        
        # Process each column directly without filtering (main view)
        for column in columns.values():
            if column.data_type is None or column.data_type == "DATETIME":
                continue
                
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)
                continue
                
            # Create regular dimension
            column_name = get_column_name(column, table_format_sql, getattr(model, 'catalog_data', None), model.unique_id, is_nested_view, array_model_name)
            dimension = self.create_dimension(column, column_name)
            if dimension is not None:
                #logging.debug(f'4 added dimension to dimensions: {dimensions}')
                dimensions.append(dimension)
        
        return dimensions, nested_dimensions

    def _generate_dimensions_from_columns(
        self,
        model: DbtModel,
        columns: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from a pre-filtered set of columns.
        
        This eliminates the need for include_names/exclude_names filtering.
        """
        dimensions: List[Dict[str, Any]] = []
        nested_dimensions: List[Dict[str, Any]] = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        
        # Add ISO date dimensions for main view only
        if not is_nested_view and self._include_iso_fields:
            self._add_dimension_to_dimension_group(model, dimensions, table_format_sql)
        
        # For nested views, we need to replicate the complex logic from the legacy approach
        if is_nested_view and array_model_name:
            # Find the array model column
            array_model_column = model.columns.get(array_model_name)
            return self._generate_nested_view_dimensions(model, columns, array_model_name, array_model_column)
        
        # Process each column directly without filtering (main view)
        for column in columns.values():
            if column.data_type is None or column.data_type == "DATETIME":
                continue
                
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)
                continue
                
            # Create regular dimension
            column_name = get_column_name(column, table_format_sql, getattr(model, '_catalog_data', None), model.unique_id, is_nested_view, array_model_name)
            dimension = self.create_dimension(column, column_name, model)
            if dimension is not None:
                dimensions.append(dimension)
        
        return dimensions, nested_dimensions

    def _generate_nested_view_dimensions(
        self,
        model: DbtModel,
        columns: Dict[str, DbtModelColumn],
        array_model_name: str,
        array_model_column: DbtModelColumn = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions for nested views with proper naming transformations."""
        dimensions: List[Dict[str, Any]] = []
        nested_dimensions: List[Dict[str, Any]] = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        processed_columns = set()
        
        # Build hierarchy map to identify nested arrays
        def build_hierarchy_map(columns):
            """Build a map of parent -> children relationships based on dot notation."""
            hierarchy = {}
            for col in columns.values():
                parts = col.name.split('.')
                for i in range(len(parts)):
                    parent_path = '.'.join(parts[:i+1])
                    if parent_path not in hierarchy:
                        hierarchy[parent_path] = {
                            'children': set(),
                            'is_array': col.data_type and 'ARRAY' in str(col.data_type).upper() if i == len(parts) - 1 else False,
                            'column': col if i == len(parts) - 1 else None
                        }
                    
                    # Add child relationships
                    if i < len(parts) - 1:
                        child_path = '.'.join(parts[:i+2])
                        hierarchy[parent_path]['children'].add(child_path)
            return hierarchy
        
        hierarchy = build_hierarchy_map(model.columns)
        
        # Add nested array dimensions to nested view as hidden dimensions
        for col_name, column in columns.items():
            if col_name.startswith(f"{array_model_name}.") and column.data_type:
                data_type_str = str(column.data_type).upper()
                if data_type_str.startswith('ARRAY') and len(hierarchy.get(col_name, {}).get('children', set())) > 0:
                    # This is a nested array within the current array - add as hidden dimension to current view
                    nested_column_name = get_column_name(column, table_format_sql, getattr(model, '_catalog_data', None), model.unique_id, True, array_model_name)
                    
                    # Create dimension with prefix stripping for nested views
                    fake_include_names = [f"{array_model_name}.dummy"]  # Simulate include_names with dotted name for naming
                    nested_dimension = self.create_dimension(column, nested_column_name, include_names=fake_include_names)
                    if nested_dimension is not None:
                        if 'dangerous' in nested_dimension.get('name', '').lower():
                            logging.debug(f'Created nested array dimension in dimension.py: {nested_dimension}')
                            logging.debug(f'Column name: {col_name}, nested_column_name: {nested_column_name}')
                        nested_dimension['hidden'] = 'yes'
                        # Add to regular dimensions so they appear in current view
                        dimensions.append(nested_dimension)
                        # Add to nested_dimensions so they create their own nested views
                        nested_dimensions.append({
                            'name': nested_dimension['name'],
                            'column': column,
                            'array_model_name': col_name
                        })
                        processed_columns.add(col_name)
        
        # Process regular columns
        for col_name, column in columns.items():
            if col_name in processed_columns or column.data_type is None or column.data_type == "DATETIME":
                continue
                
            if column.data_type == "DATE":
                continue  # Skip date dimensions for now
            
            # For nested views, handle the parent array field specially
            parent = array_model_name
            if col_name == parent:
                # Check if this is a single value array (ARRAY<primitive>) or array with struct
                catalog_data = getattr(model, '_catalog_data', None)
                original_name = getattr(column, 'original_name', None)
                catalog_column = get_catalog_column_info(col_name, catalog_data, model.unique_id, original_name)
                
                is_single_value_array_type = is_single_value_array(catalog_column)
                
                # For single value arrays, always include array field dimension
                # For ARRAY<STRUCT>, only include for top-level arrays
                is_top_level_array = '.' not in array_model_name
                should_include_array_dimension = is_single_value_array_type or is_top_level_array
                
                if should_include_array_dimension:
                    # Include the array parent field itself as a hidden dimension in its nested view
                    # The dimension name should match the nested view name pattern
                    
                    # Get the base model name from the model
                    if hasattr(model, 'relation_name') and model.relation_name:
                        table_name = model.relation_name.split('.')[-1].strip('`')
                        base_name = camel_to_snake(table_name)
                    else:
                        base_name = model.name
                    
                    # Use the array model column's lookml_long_name if available
                    if array_model_column and hasattr(array_model_column, 'lookml_long_name') and array_model_column.lookml_long_name:
                        array_field_name = array_model_column.lookml_long_name
                    else:
                        # Fallback to converting the array_model_name
                        array_field_name = camel_to_snake(array_model_name.replace('.', '_'))
                    
                    # Construct dimension name to match nested view name pattern
                    dimension_name = f"{base_name}__{array_field_name}".lower()
                    
                    # Rule: if using dimension_name as SQL reference, don't add ${TABLE}. prefix
                    sql_reference = dimension_name
                    
                    # Determine the correct type for the array field dimension
                    looker_type = get_array_element_looker_type(catalog_column)
                    
                    dimension = {
                        'name': dimension_name,
                        'type': looker_type,
                        'hidden': 'yes',
                        'sql': sql_reference
                    }
                    dimensions.append(dimension)
                
                processed_columns.add(col_name)
                continue
            
            processed_columns.add(col_name)
            #logging.debug(f"adding column {col_name} to processed")
            
            # Check if this is a date/time field that should be a dimension group
            looker_type = self._get_looker_type(column)
            if looker_type in ("time", "date"):
                # Create dimension group for date/time fields in nested views
                dimension_group, dimension_group_set, dimension_group_dimensions = self.lookml_dimension_group(
                    column=column,
                    looker_type=looker_type,
                    table_format_sql=table_format_sql,
                    model=model,
                    is_nested_view=True,
                    array_model_name=array_model_name,
                )
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)
                continue
            
            # Get column name for SQL
            column_name = get_column_name(column, table_format_sql, getattr(model, 'catalog_data', None), model.unique_id, True, array_model_name)
            
            # For nested views, always use include_names logic to strip the array model prefix
            fake_include_names = [f"{array_model_name}.dummy"]
            dimension = self.create_dimension(column, column_name, include_names=fake_include_names)
            
            if dimension is not None:
                if 'dangerous' in dimension.get('name', '').lower():
                    logging.debug(f'Created regular dimension in nested view: {dimension}')
                    logging.debug(f'Column: {col_name}, column_name: {column_name}')
                dimensions.append(dimension)
                #logging.debug(f'3 added dimension to dimensions {dimension}')
        return dimensions, nested_dimensions

    def lookml_dimension_groups_from_model(
        self,
        model: DbtModel,
        columns_subset: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Dict[str, Any]:
        """Generate dimension groups from model using pre-filtered columns.
        Args:
            model: Model to generate dimension groups from
            columns_subset: Pre-filtered columns to generate dimension groups from
            is_nested_view: Whether this is for a nested view (affects SQL format)
            array_model_name: Name of array model for nested views (for prefix stripping)
        Returns:
            Dictionary containing dimension groups and dimension group sets
        """
        dimension_groups = []
        dimension_group_sets = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        for column in columns_subset.values():
            looker_type = self._get_looker_type(column)
            if looker_type in ("time", "date"):
                dimension_group, dimension_group_set, dimensions = self.lookml_dimension_group(
                    column=column,
                    looker_type=looker_type,
                    table_format_sql=table_format_sql,
                    model=model,
                    is_nested_view=is_nested_view,
                    array_model_name=array_model_name,
                )
                if dimension_group:
                    dimension_groups.append(dimension_group)
                if dimension_group_set:
                    dimension_group_sets.append(dimension_group_set)
        return {
            "dimension_groups": dimension_groups or None,
            "dimension_group_sets": dimension_group_sets or None,
        }
