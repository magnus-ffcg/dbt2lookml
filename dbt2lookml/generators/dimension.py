"""LookML dimension generator module."""

import logging
from typing import Any, Dict, List, Optional, Tuple

from dbt2lookml.enums import LookerDateTimeframes, LookerDateTimeTypes, LookerDateTypes, LookerScalarTypes, LookerTimeTimeframes
from dbt2lookml.generators.utils import get_column_name, map_bigquery_to_looker
from dbt2lookml.models.dbt import DbtModel, DbtModelColumn

from . import utils


class LookmlDimensionGenerator:
    """Lookml dimension generator."""

    def __init__(self, args):
        """Initialize the generator with CLI arguments."""
        self._cli_args = args
        self._custom_timeframes = getattr(args, 'timeframes', {})
        self._include_iso_fields = getattr(args, 'include_iso_fields', False)

    def _get_conflicting_timeframes(
        self,
        dimension_group: Dict[str, Any],
        existing_dimension_names: set,
        original_column_name: str = None,
    ) -> List[str]:
        """Get timeframes that would conflict with existing dimensions.
        Args:
            dimension_group: The dimension group to check
            existing_dimension_names: Set of existing dimension names
            original_column_name: Original column name before _date removal
        Returns:
            List of timeframes that would create conflicts
        """
        group_name = dimension_group.get("name")
        group_type = dimension_group.get("type")
        if not (group_name and group_type == "time"):
            return []
        # Determine if this is a date or time dimension group
        looker_type = "date" if dimension_group.get("datatype") == "date" else "time"
        # Use enum values for timeframes
        if looker_type == "date":
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
        elif looker_type == "time":
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
        else:
            return []
        # Find conflicting timeframes
        conflicting_timeframes = []
        for timeframe in timeframes:
            generated_name = f"{group_name}_{timeframe}"
            # Check for direct conflicts with the generated name
            if generated_name in existing_dimension_names:
                conflicting_timeframes.append(timeframe)
            # Special case: check if original column name would conflict with this timeframe
            elif (
                original_column_name
                and original_column_name in existing_dimension_names
                and original_column_name == generated_name
            ):
                # Only conflict if the original column name exactly matches what would be generated
                conflicting_timeframes.append(timeframe)
        return conflicting_timeframes


    def _comment_conflicting_dimensions(
        self, dimensions: List[Dict[str, Any]], dimension_groups: List[Dict[str, Any]], model_name: str = None
    ) -> List[Dict[str, Any]]:
        """Comment out regular dimensions that conflict with dimension groups.
        Args:
            dimensions: List of regular dimensions to process
            dimension_groups: List of dimension groups to check against
        Returns:
            List of dimensions with conflicts commented out
        """
        # Build set of all dimension names that would be generated by dimension groups
        dimension_group_generated_names = set()
        dimension_group_base_names = set()
        
        for dim_group in dimension_groups:
            group_name = dim_group.get("name")
            group_type = dim_group.get("type")
            timeframes = dim_group.get("timeframes", [])
            
            # Add the base dimension group name
            dimension_group_base_names.add(group_name)
            
            # Add all timeframe variants
            for timeframe in timeframes:
                if not timeframe.startswith("#"):  # Skip commented timeframes
                    dimension_group_generated_names.add(f"{group_name}_{timeframe}")
        
        # Process regular dimensions and comment out conflicts
        conflicting_dimensions = []
        processed_dimensions = []
        for dimension in dimensions:
            dim_name = dimension.get("name")
            
            # Check for conflicts
            is_conflicting = (
                dim_name in dimension_group_generated_names or
                dim_name in dimension_group_base_names
            )
            
            if is_conflicting:
                # Comment out the entire dimension
                conflicting_dimensions.append(dim_name)
                if model_name:
                    logging.debug(f"Removed conflicting dimension '{dim_name}' from model '{model_name}'")
                else:
                    logging.debug(f"Removed conflicting dimension: {dim_name}")
            else:
                #logging.debug(f'6. adding dimensions to process dimensions: {dimension}')
                processed_dimensions.append(dimension)
        
        return processed_dimensions, conflicting_dimensions
    
    def _comment_conflicting_timeframes(self, dimensions: List[Dict[str, Any]], dimension_groups: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Comment out timeframes in dimension groups that conflict with existing dimensions.
        Args:
            dimensions: List of regular dimensions to check against
            dimension_groups: List of dimension groups to process
        Returns:
            List of dimension groups with conflicting timeframes commented out
        """
        # Build set of existing dimension names
        existing_names = {dim.get('name') for dim in dimensions}
        
        processed_groups = []
        for dim_group in dimension_groups:
            group_name = dim_group.get('name')
            timeframes = dim_group.get('timeframes', [])
            
            # Process timeframes and comment out conflicts
            processed_timeframes = []
            for timeframe in timeframes:
                if timeframe.startswith('#'):
                    # Already commented, keep as is
                    processed_timeframes.append(timeframe)
                else:
                    # Check if this timeframe would conflict
                    generated_name = f"{group_name}_{timeframe}"
                    if generated_name in existing_names:
                        # Comment out conflicting timeframe
                        processed_timeframes.append(f"# {timeframe}")
                    else:
                        # Keep active timeframe
                        processed_timeframes.append(timeframe)
            
            # Create new dimension group with processed timeframes
            processed_group = dim_group.copy()
            processed_group['timeframes'] = processed_timeframes
            processed_groups.append(processed_group)
        
        return processed_groups

    def _clean_dimension_groups_for_output(self, dimension_groups: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove internal fields from dimension groups before LookML output.
        Args:
            dimension_groups: List of dimension groups to clean
        Returns:
            List of dimension groups with internal fields removed
        """
        cleaned_groups = []
        for dim_group in dimension_groups:
            cleaned_group = {}
            # Copy only valid LookML fields, excluding internal tracking fields
            for key, value in dim_group.items():
                if not key.startswith("_"):
                    cleaned_group[key] = value
            cleaned_groups.append(cleaned_group)
        return cleaned_groups

    def _format_label(self, name: Optional[str] = None, remove_date: bool = True) -> str:
        """Format a name into a human-readable label.
        Args:
            name: The name to format
            remove_date: Whether to remove '_date' from the name
        Returns:
            Formatted label string
        """
        if name is None:
            return ""
        
        # Remove date suffix if requested
        if remove_date:
            if name.endswith('Date'):
                name = name[:-4]
            elif name.endswith('_date'):
                name = name[:-5]
        
        # Convert CamelCase to snake_case first, then to readable format
        from dbt2lookml.utils import camel_to_snake
        snake_case = camel_to_snake(name)
        return snake_case.replace("_", " ").title()

    def _apply_meta_looker_attributes(self, target_dict: Dict[str, Any], column: DbtModelColumn, attributes: List[str]) -> None:
        """Apply meta attributes from column to target dictionary if they exist.
        Args:
            target_dict: Dictionary to update with meta attributes
            column: Column containing meta attributes
            attributes: List of attribute names to apply
        """
        if column.meta and column.meta.looker and column.meta.looker.dimension is not None:
            for attr in attributes:
                value = getattr(column.meta.looker.dimension, attr, None)
                if value is not None:
                    if attr == "value_format_name":
                        meta_value = value.value
                    elif isinstance(value, bool):
                        meta_value = "yes" if value else "no"
                    else:
                        meta_value = value
                    target_dict[attr] = meta_value

    def _create_iso_field(self, field_type: str, column: DbtModelColumn, sql: str) -> Dict[str, Any]:
        """Create an ISO year or week field.
        Args:
            field_type: Type of ISO field (year or week)
            column: Column to create field from
            sql: SQL expression for the field
        Returns:
            Dictionary containing ISO field definition
        """
        label_type = field_type.replace("_of_year", "")
        field = {
            "name": f"{column.name}_iso_{field_type}",
            "label": f"{self._format_label(column.name)} ISO {label_type.title()}",
            "type": "number",
            "sql": f"Extract(iso{label_type} from {sql})",
            "description": f"iso year for {column.name}",
            "group_label": "D Date",
            "value_format_name": "id",
        }
        self._apply_meta_looker_attributes(field, column, ["group_label", "label"])
        if field_type == "week_of_year":
            field["label"] = field["label"].replace("Week", "Week Of Year")
        return field

    def _get_looker_type(self, column: DbtModelColumn) -> str:
        """Get the category of a column's type.
        Args:
            column: Column to get type for
        Returns:
            Type category (scalar, date, time)
        """
        looker_type = map_bigquery_to_looker(column.data_type)
        if looker_type in LookerDateTimeTypes.values():
            return "time"
        elif looker_type in LookerDateTypes.values():
            return "date"
        return "scalar"

    def _create_dimension(self, column: DbtModelColumn, sql: str, is_hidden: bool = False, include_names: Optional[List[str]] = None) -> Optional[Dict[str, Any]]:
        """Create a basic dimension dictionary.
        Args:
            column: Column to create dimension from
            sql: SQL expression for the dimension
            is_hidden: Whether the dimension is hidden
        Returns:
            Dictionary containing dimension definition
        """
        data_type = map_bigquery_to_looker(column.data_type)
        if data_type is None:
            return None
        # Determine dimension name based on context
        if column.nested:
            # Always use lookml_long_name for nested fields in main view
            # This handles both struct fields like "classification.assortment.code" -> "classification__assortment__code"
            # and array elements that should be in main view
            dimension_name = column.lookml_long_name
        else:
            # Use lookml_name for regular columns
            dimension_name = column.lookml_name

        # Apply naming conventions for nested views to match fixture expectations
        if include_names and any('.' in name for name in include_names):
            # For nested views, strip the array model prefix from dimension names
            # Extract array model name from include_names (format: "array.model.name.dummy")
            array_model_from_include = include_names[0].rsplit('.', 1)[0]  # Remove ".dummy"
            
            logging.debug(f"Nested view dimension naming - Column: {column.name}")
            logging.debug(f"  Original dimension_name: {dimension_name}")
            logging.debug(f"  Array model from include: {array_model_from_include}")
            
            # Convert the full array model path to match lookml_long_name format
            # Extract the actual prefix from the current column's lookml_long_name
            from dbt2lookml.utils import camel_to_snake

            # The array model has N parts, so we need to strip the first N parts from lookml_long_name
            array_parts_count = len(array_model_from_include.split('.'))
            dimension_parts = dimension_name.split('__')
            
            logging.debug(f"  Array model from include: {array_model_from_include}")
            logging.debug(f"  Array parts count: {array_parts_count}")
            logging.debug(f"  Dimension parts: {dimension_parts}")
            
            # Strip the first N parts that correspond to the array model
            if len(dimension_parts) > array_parts_count:
                stripped_parts = dimension_parts[array_parts_count:]
                dimension_name = '__'.join(stripped_parts)
                logging.debug(f"  After stripping {array_parts_count} prefix parts: {dimension_name}")
            elif '__' in dimension_name:
                # Fallback: strip the first prefix for backward compatibility
                import re
                original_name = dimension_name
                dimension_name = re.sub(r'^.*?__', '', dimension_name)
                logging.debug(f"  Fallback stripping first prefix: {original_name} -> {dimension_name}")
            
            logging.debug(f"  Final dimension name: {dimension_name}")
        
        else:
            # For non-nested views, convert dots to double underscores and apply camelCase conversion
            # Use original_name if available to get the proper camelCase format
            source_name = getattr(column, 'original_name', column.name) or column.name
            
            if '.' in source_name:
                # Convert dots to double underscores: Classification.ItemGroup.Code -> classification__item_group__code
                parts = source_name.split('.')
                from dbt2lookml.utils import camel_to_snake
                snake_parts = [camel_to_snake(part).lower() for part in parts]
                dimension_name = '__'.join(snake_parts)
            else:
                # Apply camelCase conversion for single names
                from dbt2lookml.utils import camel_to_snake
                dimension_name = camel_to_snake(source_name).lower()

        dimension: Dict[str, Any] = {"name": utils.safe_name(dimension_name)}
        # Add type for scalar types (should come before sql)
        if data_type in LookerScalarTypes.values():
            dimension["type"] = data_type
        dimension |= {"sql": sql}

        # Add group labels for nested fields in main view
        if column.nested and '.' in column.name:
            parts = column.name.split('.')
            if len(parts) >= 2:
                # Create dynamic group label from all parts except the last one
                group_parts = parts[:-1]
                group_label = self._create_group_label(group_parts)
                dimension["group_label"] = group_label

                # Add group item label from the last part
                # Use original_name if available to preserve CamelCase, otherwise fall back to name
                if column.original_name and '.' in column.original_name:
                    original_parts = column.original_name.split('.')
                    if len(original_parts) == len(parts):
                        last_part = original_parts[-1]
                    else:
                        last_part = parts[-1]
                else:
                    last_part = parts[-1]
                dimension["group_item_label"] = self._create_item_label(last_part)

        # Add primary key attributes
        if column.is_primary_key:
            dimension["primary_key"] = "yes"
            dimension["hidden"] = "yes"
            dimension["value_format_name"] = "id"
        elif is_hidden:
            dimension["hidden"] = "yes"
        # Mark deeply nested struct fields as hidden (3+ levels of nesting)
        elif column.nested and len(column.name.split('.')) >= 3:
            dimension["hidden"] = "yes"
        # Handle array and struct types
        if "ARRAY" in f"{column.data_type}":
            dimension["hidden"] = "yes"
            dimension["tags"] = ["array"]
            dimension.pop("type", None)
        elif "STRUCT" in f"{column.data_type}":
            dimension["hidden"] = "yes"
            dimension["tags"] = ["struct"]
        # Apply meta looker attributes
        self._apply_meta_looker_attributes(
            dimension,
            column,
            ["description", "group_label", "value_format_name", "label", "hidden"],
        )
        return dimension

    def lookml_dimension_group(
        self, column: DbtModelColumn, looker_type: str, table_format_sql: bool, model: DbtModel, is_nested_view: bool = False, array_model_name: str = None
    ) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]], List[Dict[str, Any]]]:
        """Create dimension group for date/time fields.
        Args:
            column: Column to create dimension group from
            looker_type: Type of dimension group (date, time)
            table_format_sql: Whether to format SQL for table
            model: Model containing column
            is_nested_view: Whether this is for a nested view (affects naming)
            array_model_name: Name of array model for nested views (for prefix stripping)
        Returns:
            Tuple containing dimension group, dimension group set, and dimensions
        """
        if map_bigquery_to_looker(column.data_type) is None:
            return None, None, None
        if looker_type == "date":
            convert_tz = "no"
            # Use enum values for timeframes
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
            column_name_adjusted = self._transform_date_column_name(column, is_nested_view, array_model_name)
        elif looker_type == "time":
            convert_tz = "yes"
            # Use enum values for timeframes
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
            column_name_adjusted = self._transform_date_column_name(column, is_nested_view, array_model_name)
        else:
            return None, None, None
        sql = get_column_name(column, table_format_sql, getattr(model, '_catalog_data', None), model.unique_id)
        dimensions = []
        # Use original_name for proper formatting if available, otherwise use column name
        label_source = getattr(column, 'original_name', column.name)
        
        # For nested fields, separate the label and group_label
        if '.' in label_source:
            parts = label_source.split('.')
            # Label is just the last part (field name)
            field_label = self._format_label(parts[-1], remove_date=False)
            # Group label is the parent parts
            group_parts = parts[:-1]
            group_label = self._create_group_label(group_parts)
        else:
            # For non-nested fields, label and group_label are the same
            field_label = self._format_label(label_source, remove_date=False)
            group_label = field_label
        
        dimension_group = {
            "name": utils.safe_name(column_name_adjusted),
            "label": field_label,
            "type": 'time',
            "sql": sql,
            "datatype": map_bigquery_to_looker(column.data_type),
            "timeframes": timeframes,
            "group_label": ("D Date" if column_name_adjusted == "d" else group_label),
            "convert_tz": convert_tz,
            "_original_column_name": column.name,  # Store original column name for conflict detection
        }
        # Only add description if it's not None
        if column.description is not None:
            dimension_group["description"] = column.description
        self._apply_meta_looker_attributes(dimension_group, column, ["group_label", "label"])
        dimension_group_set = {
            "name": f"s_{column_name_adjusted}",
            "fields": [f"{column_name_adjusted}_{looker_time_timeframe}" for looker_time_timeframe in timeframes],
        }
        if looker_type == "date" and self._include_iso_fields:
            iso_year = self._create_iso_field("year", column, sql)
            iso_week_of_year = self._create_iso_field("week_of_year", column, sql)
            dimensions = [iso_year, iso_week_of_year]
            dimension_group_set["fields"].extend([f"{column.name}_iso_year", f"{column.name}_iso_week_of_year"])
        return dimension_group, dimension_group_set, dimensions

    def _transform_date_column_name(self, column: DbtModelColumn, is_nested_view: bool = False, array_model_name: str = None) -> str:
        """Transform date column names to dimension group names.

        Removes 'Date' or 'date' suffix and converts to snake_case.
        Handles nested fields by processing each part separately.
        Only converts what can be reliably converted (CamelCase and nested fields).
        For nested views, strips the nested view prefix from dimension group names.

        Examples:
            DeliveryStartDate -> delivery_start (CamelCase conversion)
            deliverystartdate -> deliverystartdate (lowercase - keep as-is)
            format.period.EndDate -> format__period__end (nested fields)
            returnable_assets_deposit__returnable_asset_deposit_end -> returnable_asset_deposit_end (nested view)
        """
        from dbt2lookml.utils import camel_to_snake

        # Use original name to preserve CamelCase for proper conversion
        column_name = column.original_name or column.name

        # Handle nested fields first
        if '.' in column_name:
            parts = column_name.split('.')
            snake_parts = []
            for i, part in enumerate(parts):
                # Only remove date suffix from the last part (actual column name)
                if i == len(parts) - 1:  # Last part
                    if part.endswith('Date'):
                        part = part[:-4]  # Remove 'Date'
                    elif part.endswith('_date'):
                        part = part[:-5]  # Remove '_date'
                    elif part.lower().endswith('date'):
                        part = part[:-4]  # Remove 'date'

                # Apply the same realistic conversion logic to each part
                if part.islower() and '_' not in part:
                    # Pure lowercase - keep as-is
                    snake_parts.append(part)
                else:
                    # CamelCase or snake_case - convert
                    snake_parts.append(camel_to_snake(part))
            result = '__'.join(snake_parts)
        else:
            # Single field - remove date suffix first, then segment and convert
            # Special case: if column name is exactly "Date", don't remove the suffix
            if column_name == 'Date':
                result = 'date'  # Keep as 'date' for dimension_group name
            elif column_name == 'date':
                result = 'date'  # Keep as 'date' for dimension_group name
            elif column_name.endswith('Date'):
                base_name = column_name[:-4]  # Remove 'Date'
                # Clean up trailing underscores from base_name first
                base_name = base_name.rstrip('_')
                
                # Only convert what we can reliably handle
                if base_name.islower() and '_' not in base_name:
                    # Pure lowercase concatenated words - keep as-is
                    result = base_name
                else:
                    # CamelCase or snake_case - can convert reliably
                    result = camel_to_snake(base_name)
            elif column_name.lower().endswith('date'):
                base_name = column_name[:-4]  # Remove 'date' or '_date'
                # Clean up trailing underscores from base_name first
                base_name = base_name.rstrip('_')
                
                # Only convert what we can reliably handle
                if base_name.islower() and '_' not in base_name:
                    # Pure lowercase concatenated words - keep as-is
                    result = base_name
                else:
                    # CamelCase or snake_case - can convert reliably
                    result = camel_to_snake(base_name)
            else:
                base_name = column_name
                # Only convert what we can reliably handle
                if base_name.islower() and '_' not in base_name:
                    # Pure lowercase concatenated words - keep as-is
                    result = base_name
                else:
                    # CamelCase or snake_case - can convert reliably
                    result = camel_to_snake(base_name)

        # Clean up any trailing underscores
        result = result.rstrip('_')
        
        # For nested views, strip the nested view prefix from dimension group names
        if is_nested_view and array_model_name:
            logging.debug(f"Dimension group naming - Column: {column.name}")
            logging.debug(f"  Original result: {result}")
            logging.debug(f"  Array model name: {array_model_name}")
            
            # Strip the array model prefix from dimension group names
            # The array model has N parts, so we need to strip the first N parts
            array_parts_count = len(array_model_name.split('.'))
            result_parts = result.split('__')
            
            logging.debug(f"  Array model name: {array_model_name}")
            logging.debug(f"  Array parts count: {array_parts_count}")
            logging.debug(f"  Result parts: {result_parts}")
            
            # Strip the first N parts that correspond to the array model
            if len(result_parts) > array_parts_count:
                stripped_parts = result_parts[array_parts_count:]
                result = '__'.join(stripped_parts)
                logging.debug(f"  After stripping {array_parts_count} prefix parts: {result}")
            else:
                logging.debug(f"  Not enough parts to strip, keeping original: {result}")
        
        return result

    def _get_dimension_group_generated_names(self, column_name: str, looker_type: str) -> List[str]:
        """Get all dimension names that would be generated by a dimension group.
        Args:
            column_name: Base name of the column (with _date suffix removed)
            looker_type: Type of dimension group (date or time)
        Returns:
            List of dimension names that would be generated
        """
        if looker_type == "date":
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
        elif looker_type == "time":
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
        else:
            return []
        return [f"{column_name}_{timeframe}" for timeframe in timeframes]

    def _create_group_label(self, parts: list[str]) -> str:
        """Create a human-readable group label from nested field parts.

        Args:
            parts: List of field name parts (e.g., ['classification', 'assortment'])

        Returns:
            Formatted group label (e.g., 'Classification Assortment')
        """
        # Convert each part to title case, handling common patterns
        formatted_parts = []
        for part in parts:
            from dbt2lookml.utils import camel_to_snake

            snake_case = camel_to_snake(part)
            title_case = snake_case.replace('_', ' ').capitalize()
            formatted_parts.append(title_case)

        return ' '.join(formatted_parts)

    def _create_item_label(self, item: str) -> str:
        from dbt2lookml.utils import camel_to_snake

        snake_case = camel_to_snake(item)
        return snake_case.replace('_', ' ').capitalize()

    def _create_single_array_dimension(self, column: DbtModelColumn) -> Dict[str, Any]:
        """Create a dimension for a simple array type.
        Args:
            column: Column to create dimension from
        Returns:
            Dictionary containing dimension definition
        """
        data_type = map_bigquery_to_looker(column.inner_types[0])
        return {
            "name": column.lookml_name,
            "type": data_type,
            "sql": column.lookml_name,
            "description": column.description or "",
        }

    def _is_single_type_array(self, column: DbtModelColumn) -> bool:
        """Check if column is a simple array type.
        Args:
            column: Column to check
        Returns:
            Whether column is a simple array type
        """
        return column.data_type == "ARRAY" and (len(column.inner_types) == 1 and " " not in column.inner_types[0])

    def _add_dimension_to_dimension_group(self, model: DbtModel, dimensions: List[Dict[str, Any]], table_format_sql: bool = True):
        """Add dimensions to dimension groups.
        Args:
            model: Model containing dimensions
            dimensions: List of dimensions to add
            table_format_sql: Whether to format SQL for table
        """
        for column in model.columns.values():
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model, False, None)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)

    def lookml_dimensions_from_model(
        self,
        model: DbtModel,
        columns_subset: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from model using pre-filtered columns.
        Args:
            model: Model to generate dimensions from
            columns_subset: Pre-filtered columns to generate dimensions from
            is_nested_view: Whether this is for a nested view (affects naming)
            array_model_name: Name of array model for nested views (for naming)
        Returns:
            Tuple containing dimensions and nested dimensions
        """
        return self._generate_dimensions_from_columns(model, columns_subset, is_nested_view, array_model_name)

    def _generate_dimensions_from_columns(
        self,
        model: DbtModel,
        columns: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from a pre-filtered set of columns.
        
        This eliminates the need for include_names/exclude_names filtering.
        """
        dimensions: List[Dict[str, Any]] = []
        nested_dimensions: List[Dict[str, Any]] = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        
        # Add ISO date dimensions for main view only
        if not is_nested_view and self._include_iso_fields:
            self._add_dimension_to_dimension_group(model, dimensions, table_format_sql)
        
        # For nested views, we need to replicate the complex logic from the legacy approach
        if is_nested_view and array_model_name:
            # Find the array model column
            array_model_column = model.columns.get(array_model_name)
            return self._generate_nested_view_dimensions(model, columns, array_model_name, array_model_column)
        
        # Process each column directly without filtering (main view)
        for column in columns.values():
            if column.data_type is None or column.data_type == "DATETIME":
                continue
                
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)
                continue
                
            # Create regular dimension
            from dbt2lookml.generators.utils import get_column_name
            column_name = get_column_name(column, table_format_sql, getattr(model, 'catalog_data', None), model.unique_id, is_nested_view, array_model_name)
            dimension = self._create_dimension(column, column_name)
            if dimension is not None:
                #logging.debug(f'4 added dimension to dimensions: {dimensions}')
                dimensions.append(dimension)
        
        return dimensions, nested_dimensions

    def _generate_dimensions_from_columns(
        self,
        model: DbtModel,
        columns: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from a pre-filtered set of columns.
        
        This eliminates the need for include_names/exclude_names filtering.
        """
        dimensions: List[Dict[str, Any]] = []
        nested_dimensions: List[Dict[str, Any]] = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        
        # Add ISO date dimensions for main view only
        if not is_nested_view and self._include_iso_fields:
            self._add_dimension_to_dimension_group(model, dimensions, table_format_sql)
        
        # For nested views, we need to replicate the complex logic from the legacy approach
        if is_nested_view and array_model_name:
            # Find the array model column
            array_model_column = model.columns.get(array_model_name)
            return self._generate_nested_view_dimensions(model, columns, array_model_name, array_model_column)
        
        # Process each column directly without filtering (main view)
        for column in columns.values():
            if column.data_type is None or column.data_type == "DATETIME":
                continue
                
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)
                continue
                
            # Create regular dimension
            from dbt2lookml.generators.utils import get_column_name
            column_name = get_column_name(column, table_format_sql, getattr(model, 'catalog_data', None), model.unique_id, is_nested_view, array_model_name)
            dimension = self._create_dimension(column, column_name)
            if dimension is not None:
                dimensions.append(dimension)
                #logging.debug(f'2. added dimension to dimensions: {dimension}')
        
        return dimensions, nested_dimensions

    def _generate_nested_view_dimensions(
        self,
        model: DbtModel,
        columns: Dict[str, DbtModelColumn],
        array_model_name: str,
        array_model_column: DbtModelColumn = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions for nested views with proper naming transformations."""
        dimensions: List[Dict[str, Any]] = []
        nested_dimensions: List[Dict[str, Any]] = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        processed_columns = set()
        
        # Build hierarchy map to identify nested arrays
        def build_hierarchy_map(columns):
            """Build a map of parent -> children relationships based on dot notation."""
            hierarchy = {}
            for col in columns.values():
                parts = col.name.split('.')
                for i in range(len(parts)):
                    parent_path = '.'.join(parts[:i+1])
                    if parent_path not in hierarchy:
                        hierarchy[parent_path] = {
                            'children': set(),
                            'is_array': col.data_type and 'ARRAY' in str(col.data_type).upper() if i == len(parts) - 1 else False,
                            'column': col if i == len(parts) - 1 else None
                        }
                    
                    # Add child relationships
                    if i < len(parts) - 1:
                        child_path = '.'.join(parts[:i+2])
                        hierarchy[parent_path]['children'].add(child_path)
            return hierarchy
        
        hierarchy = build_hierarchy_map(model.columns)
        
        # Add nested array dimensions to nested view as hidden dimensions
        for col_name, column in columns.items():
            if col_name.startswith(f"{array_model_name}.") and column.data_type:
                data_type_str = str(column.data_type).upper()
                if data_type_str.startswith('ARRAY') and len(hierarchy.get(col_name, {}).get('children', set())) > 0:
                    # This is a nested array within the current array - add as hidden dimension to current view
                    from dbt2lookml.generators.utils import get_column_name
                    nested_column_name = get_column_name(column, table_format_sql, getattr(model, '_catalog_data', None), model.unique_id, True, array_model_name)
                    
                    # Create dimension with prefix stripping for nested views
                    fake_include_names = [f"{array_model_name}.dummy"]  # Simulate include_names with dotted name for naming
                    nested_dimension = self._create_dimension(column, nested_column_name, include_names=fake_include_names)
                    if nested_dimension is not None:
                        if 'dangerous' in nested_dimension.get('name', '').lower():
                            logging.debug(f'Created nested array dimension in dimension.py: {nested_dimension}')
                            logging.debug(f'Column name: {col_name}, nested_column_name: {nested_column_name}')
                        nested_dimension['hidden'] = 'yes'
                        # Add to regular dimensions so they appear in current view
                        dimensions.append(nested_dimension)
                        # Add to nested_dimensions so they create their own nested views
                        nested_dimensions.append({
                            'name': nested_dimension['name'],
                            'column': column,
                            'array_model_name': col_name
                        })
                        processed_columns.add(col_name)
        
        # Process regular columns
        for col_name, column in columns.items():
            if col_name in processed_columns or column.data_type is None or column.data_type == "DATETIME":
                continue
                
            if column.data_type == "DATE":
                continue  # Skip date dimensions for now
            
            # For nested views, handle the parent array field specially
            parent = array_model_name
            if col_name == parent:
                # Check if this is a single value array (ARRAY<primitive>) or array with struct
                from dbt2lookml.generators.utils import get_catalog_column_info, is_single_value_array
                catalog_data = getattr(model, '_catalog_data', None)
                original_name = getattr(column, 'original_name', None)
                catalog_column = get_catalog_column_info(col_name, catalog_data, model.unique_id, original_name)
                
                is_single_value_array_type = is_single_value_array(catalog_column)
                
                # For single value arrays, always include array field dimension
                # For ARRAY<STRUCT>, only include for top-level arrays
                is_top_level_array = '.' not in array_model_name
                should_include_array_dimension = is_single_value_array_type or is_top_level_array
                
                if should_include_array_dimension:
                    # Include the array parent field itself as a hidden dimension in its nested view
                    # The dimension name should match the nested view name pattern
                    
                    # Get the base model name from the model
                    from dbt2lookml.utils import camel_to_snake
                    if hasattr(model, 'relation_name') and model.relation_name:
                        table_name = model.relation_name.split('.')[-1].strip('`')
                        base_name = camel_to_snake(table_name)
                    else:
                        base_name = model.name
                    
                    # Use the array model column's lookml_long_name if available
                    if array_model_column and hasattr(array_model_column, 'lookml_long_name') and array_model_column.lookml_long_name:
                        array_field_name = array_model_column.lookml_long_name
                    else:
                        # Fallback to converting the array_model_name
                        array_field_name = camel_to_snake(array_model_name.replace('.', '_'))
                    
                    # Construct dimension name to match nested view name pattern
                    dimension_name = f"{base_name}__{array_field_name}".lower()
                    
                    # Rule: if using dimension_name as SQL reference, don't add ${TABLE}. prefix
                    sql_reference = dimension_name
                    
                    # Determine the correct type for the array field dimension
                    from dbt2lookml.generators.utils import get_array_element_looker_type
                    looker_type = get_array_element_looker_type(catalog_column)
                    
                    dimension = {
                        'name': dimension_name,
                        'type': looker_type,
                        'hidden': 'yes',
                        'sql': sql_reference
                    }
                    dimensions.append(dimension)
                
                processed_columns.add(col_name)
                continue
            
            processed_columns.add(col_name)
            #logging.debug(f"adding column {col_name} to processed")
            
            # Check if this is a date/time field that should be a dimension group
            looker_type = self._get_looker_type(column)
            if looker_type in ("time", "date"):
                # Create dimension group for date/time fields in nested views
                dimension_group, dimension_group_set, dimension_group_dimensions = self.lookml_dimension_group(
                    column=column,
                    looker_type=looker_type,
                    table_format_sql=table_format_sql,
                    model=model,
                    is_nested_view=True,
                    array_model_name=array_model_name,
                )
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)
                continue
            
            # Get column name for SQL
            from dbt2lookml.generators.utils import get_column_name
            column_name = get_column_name(column, table_format_sql, getattr(model, 'catalog_data', None), model.unique_id, True, array_model_name)
            
            # For nested views, always use include_names logic to strip the array model prefix
            fake_include_names = [f"{array_model_name}.dummy"]
            dimension = self._create_dimension(column, column_name, include_names=fake_include_names)
            
            if dimension is not None:
                if 'dangerous' in dimension.get('name', '').lower():
                    logging.debug(f'Created regular dimension in nested view: {dimension}')
                    logging.debug(f'Column: {col_name}, column_name: {column_name}')
                dimensions.append(dimension)
                #logging.debug(f'3 added dimension to dimensions {dimension}')
        return dimensions, nested_dimensions

    def lookml_dimension_groups_from_model(
        self,
        model: DbtModel,
        columns_subset: Dict[str, DbtModelColumn],
        is_nested_view: bool = False,
        array_model_name: str = None,
    ) -> Dict[str, Any]:
        """Generate dimension groups from model using pre-filtered columns.
        Args:
            model: Model to generate dimension groups from
            columns_subset: Pre-filtered columns to generate dimension groups from
            is_nested_view: Whether this is for a nested view (affects SQL format)
            array_model_name: Name of array model for nested views (for prefix stripping)
        Returns:
            Dictionary containing dimension groups and dimension group sets
        """
        dimension_groups = []
        dimension_group_sets = []
        table_format_sql = True  # Always use ${TABLE} prefix for all views
        for column in columns_subset.values():
            looker_type = self._get_looker_type(column)
            if looker_type in ("time", "date"):
                dimension_group, dimension_group_set, dimensions = self.lookml_dimension_group(
                    column=column,
                    looker_type=looker_type,
                    table_format_sql=table_format_sql,
                    model=model,
                    is_nested_view=is_nested_view,
                    array_model_name=array_model_name,
                )
                if dimension_group:
                    dimension_groups.append(dimension_group)
                if dimension_group_set:
                    dimension_group_sets.append(dimension_group_set)
        return {
            "dimension_groups": dimension_groups or None,
            "dimension_group_sets": dimension_group_sets or None,
        }
