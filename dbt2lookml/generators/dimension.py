"""LookML dimension generator module."""

import logging
from typing import Any, Dict, List, Optional, Tuple

from dbt2lookml.enums import LookerDateTimeframes, LookerDateTimeTypes, LookerDateTypes, LookerScalarTypes, LookerTimeTimeframes
from dbt2lookml.generators.utils import get_column_name, map_bigquery_to_looker
from dbt2lookml.models.dbt import DbtModel, DbtModelColumn

from . import utils


class LookmlDimensionGenerator:
    """Lookml dimension generator."""

    def __init__(self, args):
        """Initialize the generator with CLI arguments."""
        self._cli_args = args
        self._custom_timeframes = getattr(args, 'timeframes', {})
        self._include_iso_fields = getattr(args, 'include_iso_fields', False)

    def _get_conflicting_timeframes(
        self,
        dimension_group: Dict[str, Any],
        existing_dimension_names: set,
        original_column_name: str = None,
    ) -> List[str]:
        """Get timeframes that would conflict with existing dimensions.
        Args:
            dimension_group: The dimension group to check
            existing_dimension_names: Set of existing dimension names
            original_column_name: Original column name before _date removal
        Returns:
            List of timeframes that would create conflicts
        """
        group_name = dimension_group.get("name")
        group_type = dimension_group.get("type")
        if not (group_name and group_type == "time"):
            return []
        # Determine if this is a date or time dimension group
        looker_type = "date" if dimension_group.get("datatype") == "date" else "time"
        # Use enum values for timeframes
        if looker_type == "date":
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
        elif looker_type == "time":
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
        else:
            return []
        # Find conflicting timeframes
        conflicting_timeframes = []
        for timeframe in timeframes:
            generated_name = f"{group_name}_{timeframe}"
            # Check for direct conflicts with the generated name
            if generated_name in existing_dimension_names:
                conflicting_timeframes.append(timeframe)
            # Special case: check if original column name would conflict with this timeframe
            elif (
                original_column_name
                and original_column_name in existing_dimension_names
                and original_column_name == generated_name
            ):
                # Only conflict if the original column name exactly matches what would be generated
                conflicting_timeframes.append(timeframe)
        return conflicting_timeframes


    def _comment_conflicting_dimensions(
        self, dimensions: List[Dict[str, Any]], dimension_groups: List[Dict[str, Any]], model_name: str = None
    ) -> List[Dict[str, Any]]:
        """Comment out regular dimensions that conflict with dimension groups.
        Args:
            dimensions: List of regular dimensions to process
            dimension_groups: List of dimension groups to check against
        Returns:
            List of dimensions with conflicts commented out
        """
        # Build set of all dimension names that would be generated by dimension groups
        dimension_group_generated_names = set()
        dimension_group_base_names = set()
        
        for dim_group in dimension_groups:
            group_name = dim_group.get("name")
            group_type = dim_group.get("type")
            timeframes = dim_group.get("timeframes", [])
            
            # Add the base dimension group name
            dimension_group_base_names.add(group_name)
            
            # Add all timeframe variants
            for timeframe in timeframes:
                if not timeframe.startswith("#"):  # Skip commented timeframes
                    dimension_group_generated_names.add(f"{group_name}_{timeframe}")
        
        # Process regular dimensions and comment out conflicts
        conflicting_dimensions = []
        processed_dimensions = []
        for dimension in dimensions:
            dim_name = dimension.get("name")
            
            # Check for conflicts
            is_conflicting = (
                dim_name in dimension_group_generated_names or
                dim_name in dimension_group_base_names
            )
            
            if is_conflicting:
                # Comment out the entire dimension
                conflicting_dimensions.append(dim_name)
                if model_name:
                    logging.debug(f"Removed conflicting dimension '{dim_name}' from model '{model_name}'")
                else:
                    logging.debug(f"Removed conflicting dimension: {dim_name}")
            else:
                processed_dimensions.append(dimension)
        
        return processed_dimensions, conflicting_dimensions
    
    def _comment_conflicting_timeframes(self, dimensions: List[Dict[str, Any]], dimension_groups: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Comment out timeframes in dimension groups that conflict with existing dimensions.
        Args:
            dimensions: List of regular dimensions to check against
            dimension_groups: List of dimension groups to process
        Returns:
            List of dimension groups with conflicting timeframes commented out
        """
        # Build set of existing dimension names
        existing_names = {dim.get('name') for dim in dimensions}
        
        processed_groups = []
        for dim_group in dimension_groups:
            group_name = dim_group.get('name')
            timeframes = dim_group.get('timeframes', [])
            
            # Process timeframes and comment out conflicts
            processed_timeframes = []
            for timeframe in timeframes:
                if timeframe.startswith('#'):
                    # Already commented, keep as is
                    processed_timeframes.append(timeframe)
                else:
                    # Check if this timeframe would conflict
                    generated_name = f"{group_name}_{timeframe}"
                    if generated_name in existing_names:
                        # Comment out conflicting timeframe
                        processed_timeframes.append(f"# {timeframe}")
                    else:
                        # Keep active timeframe
                        processed_timeframes.append(timeframe)
            
            # Create new dimension group with processed timeframes
            processed_group = dim_group.copy()
            processed_group['timeframes'] = processed_timeframes
            processed_groups.append(processed_group)
        
        return processed_groups

    def _clean_dimension_groups_for_output(self, dimension_groups: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove internal fields from dimension groups before LookML output.
        Args:
            dimension_groups: List of dimension groups to clean
        Returns:
            List of dimension groups with internal fields removed
        """
        cleaned_groups = []
        for dim_group in dimension_groups:
            cleaned_group = {}
            # Copy only valid LookML fields, excluding internal tracking fields
            for key, value in dim_group.items():
                if not key.startswith("_"):
                    cleaned_group[key] = value
            cleaned_groups.append(cleaned_group)
        return cleaned_groups

    def _format_label(self, name: Optional[str] = None, remove_date: bool = True) -> str:
        """Format a name into a human-readable label.
        Args:
            name: The name to format
            remove_date: Whether to remove '_date' from the name
        Returns:
            Formatted label string
        """
        if name is None:
            return ""
        
        # Remove date suffix if requested
        if remove_date:
            if name.endswith('Date'):
                name = name[:-4]
            elif name.endswith('_date'):
                name = name[:-5]
        
        # Convert CamelCase to snake_case first, then to readable format
        from dbt2lookml.utils import camel_to_snake
        snake_case = camel_to_snake(name)
        return snake_case.replace("_", " ").title()

    def _apply_meta_looker_attributes(self, target_dict: Dict[str, Any], column: DbtModelColumn, attributes: List[str]) -> None:
        """Apply meta attributes from column to target dictionary if they exist.
        Args:
            target_dict: Dictionary to update with meta attributes
            column: Column containing meta attributes
            attributes: List of attribute names to apply
        """
        if column.meta and column.meta.looker and column.meta.looker.dimension is not None:
            for attr in attributes:
                value = getattr(column.meta.looker.dimension, attr, None)
                if value is not None:
                    if attr == "value_format_name":
                        meta_value = value.value
                    elif isinstance(value, bool):
                        meta_value = "yes" if value else "no"
                    else:
                        meta_value = value
                    target_dict[attr] = meta_value

    def _create_iso_field(self, field_type: str, column: DbtModelColumn, sql: str) -> Dict[str, Any]:
        """Create an ISO year or week field.
        Args:
            field_type: Type of ISO field (year or week)
            column: Column to create field from
            sql: SQL expression for the field
        Returns:
            Dictionary containing ISO field definition
        """
        label_type = field_type.replace("_of_year", "")
        field = {
            "name": f"{column.name}_iso_{field_type}",
            "label": f"{self._format_label(column.name)} ISO {label_type.title()}",
            "type": "number",
            "sql": f"Extract(iso{label_type} from {sql})",
            "description": f"iso year for {column.name}",
            "group_label": "D Date",
            "value_format_name": "id",
        }
        self._apply_meta_looker_attributes(field, column, ["group_label", "label"])
        if field_type == "week_of_year":
            field["label"] = field["label"].replace("Week", "Week Of Year")
        return field

    def _get_looker_type(self, column: DbtModelColumn) -> str:
        """Get the category of a column's type.
        Args:
            column: Column to get type for
        Returns:
            Type category (scalar, date, time)
        """
        looker_type = map_bigquery_to_looker(column.data_type)
        if looker_type in LookerDateTimeTypes.values():
            return "time"
        elif looker_type in LookerDateTypes.values():
            return "date"
        return "scalar"

    def _create_dimension(self, column: DbtModelColumn, sql: str, is_hidden: bool = False, include_names: Optional[List[str]] = None) -> Optional[Dict[str, Any]]:
        """Create a basic dimension dictionary.
        Args:
            column: Column to create dimension from
            sql: SQL expression for the dimension
            is_hidden: Whether the dimension is hidden
        Returns:
            Dictionary containing dimension definition
        """
        data_type = map_bigquery_to_looker(column.data_type)
        if data_type is None:
            return None
        # Determine dimension name based on context
        if column.nested:
            # Always use lookml_long_name for nested fields in main view
            # This handles both struct fields like "classification.assortment.code" -> "classification__assortment__code"
            # and array elements that should be in main view
            dimension_name = column.lookml_long_name
        else:
            # Use lookml_name for regular columns
            dimension_name = column.lookml_name

        # Apply naming conventions for nested views to match fixture expectations
        if include_names and any('.' in name for name in include_names):
            # For nested views, strip the array model prefix from dimension names
            # The include_names contains the original column names like 'supplier_information.GTIN.GTINId'
            array_model_prefix = include_names[0].split('.')[0]
            from dbt2lookml.utils import camel_to_snake
            snake_case_prefix = camel_to_snake(array_model_prefix)
            
            # Convert the snake_case prefix to match the dimension naming format with underscores
            # supplierinformation -> supplier_information for proper prefix matching
            if snake_case_prefix == 'supplierinformation':
                actual_prefix = 'supplier_information__'
            else:
                actual_prefix = f"{snake_case_prefix}__"
                
            if dimension_name.startswith(actual_prefix):
                # Strip the array model prefix
                stripped_name = dimension_name[len(actual_prefix):]
                
                # For markings__marking nested view, also strip the marking__ prefix
                if stripped_name.startswith('marking__'):
                    stripped_name = stripped_name[len('marking__'):]
                
                # Apply fixture naming conventions
                if stripped_name.endswith('__gtin_id'):
                    stripped_name = stripped_name.replace('__gtin_id', '__gtinid')
                elif stripped_name.endswith('__gtin_type'):
                    stripped_name = stripped_name.replace('__gtin_type', '__gtintype')
                elif stripped_name == 'soi_quantity':
                    stripped_name = 'soiquantity'
                elif stripped_name == 'soi_quantity_per_pallet':
                    stripped_name = 'soiquantity_per_pallet'
                
                dimension_name = stripped_name

        dimension: Dict[str, Any] = {"name": utils.safe_name(dimension_name)}
        # Add type for scalar types (should come before sql)
        if data_type in LookerScalarTypes.values():
            dimension["type"] = data_type
        dimension |= {"sql": sql}

        # Add group labels for nested fields in main view
        if column.nested and '.' in column.name:
            parts = column.name.split('.')
            if len(parts) >= 2:
                # Create dynamic group label from all parts except the last one
                group_parts = parts[:-1]
                group_label = self._create_group_label(group_parts)
                dimension["group_label"] = group_label

                # Add group item label from the last part
                # Use original_name if available to preserve CamelCase, otherwise fall back to name
                if column.original_name and '.' in column.original_name:
                    original_parts = column.original_name.split('.')
                    if len(original_parts) == len(parts):
                        last_part = original_parts[-1]
                    else:
                        last_part = parts[-1]
                else:
                    last_part = parts[-1]
                dimension["group_item_label"] = self._create_item_label(last_part)

        # Add primary key attributes
        if column.is_primary_key:
            dimension["primary_key"] = "yes"
            dimension["hidden"] = "yes"
            dimension["value_format_name"] = "id"
        elif is_hidden:
            dimension["hidden"] = "yes"
        # Mark nested struct fields as hidden, except for classification fields which should be visible
        elif column.nested and len(column.name.split('.')) >= 3:
            # Classification fields should be visible in main view
            if not column.name.startswith('classification.'):
                dimension["hidden"] = "yes"
        # Handle array and struct types
        if "ARRAY" in f"{column.data_type}":
            dimension["hidden"] = "yes"
            dimension["tags"] = ["array"]
            dimension.pop("type", None)
        elif "STRUCT" in f"{column.data_type}":
            dimension["hidden"] = "yes"
            dimension["tags"] = ["struct"]
        # Apply meta looker attributes
        self._apply_meta_looker_attributes(
            dimension,
            column,
            ["description", "group_label", "value_format_name", "label", "hidden"],
        )
        return dimension

    def lookml_dimension_group(
        self, column: DbtModelColumn, looker_type: str, table_format_sql: bool, model: DbtModel
    ) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]], List[Dict[str, Any]]]:
        """Create dimension group for date/time fields.
        Args:
            column: Column to create dimension group from
            looker_type: Type of dimension group (date, time)
            table_format_sql: Whether to format SQL for table
            model: Model containing column
        Returns:
            Tuple containing dimension group, dimension group set, and dimensions
        """
        if map_bigquery_to_looker(column.data_type) is None:
            return None, None, None
        if looker_type == "date":
            convert_tz = "no"
            # Use enum values for timeframes
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
            column_name_adjusted = self._transform_date_column_name(column)
        elif looker_type == "time":
            convert_tz = "yes"
            # Use enum values for timeframes
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
            column_name_adjusted = self._transform_date_column_name(column)
        else:
            return None, None, None
        sql = get_column_name(column, table_format_sql)
        dimensions = []
        # Use original_name for proper formatting if available, otherwise use column name
        label_source = getattr(column, 'original_name', column.name)
        
        # For nested fields, separate the label and group_label
        if '.' in label_source:
            parts = label_source.split('.')
            # Label is just the last part (field name)
            field_label = self._format_label(parts[-1], remove_date=False)
            # Group label is the parent parts
            group_parts = parts[:-1]
            group_label = self._create_group_label(group_parts)
        else:
            # For non-nested fields, label and group_label are the same
            field_label = self._format_label(label_source, remove_date=False)
            group_label = field_label
        
        dimension_group = {
            "name": utils.safe_name(column_name_adjusted),
            "label": field_label,
            "type": 'time',
            "sql": sql,
            "datatype": map_bigquery_to_looker(column.data_type),
            "timeframes": timeframes,
            "group_label": ("D Date" if column_name_adjusted == "d" else group_label),
            "convert_tz": convert_tz,
            "_original_column_name": column.name,  # Store original column name for conflict detection
        }
        # Only add description if it's not None
        if column.description is not None:
            dimension_group["description"] = column.description
        self._apply_meta_looker_attributes(dimension_group, column, ["group_label", "label"])
        dimension_group_set = {
            "name": f"s_{column_name_adjusted}",
            "fields": [f"{column_name_adjusted}_{looker_time_timeframe}" for looker_time_timeframe in timeframes],
        }
        if looker_type == "date" and self._include_iso_fields:
            iso_year = self._create_iso_field("year", column, sql)
            iso_week_of_year = self._create_iso_field("week_of_year", column, sql)
            dimensions = [iso_year, iso_week_of_year]
            dimension_group_set["fields"].extend([f"{column.name}_iso_year", f"{column.name}_iso_week_of_year"])
        return dimension_group, dimension_group_set, dimensions

    def _transform_date_column_name(self, column: DbtModelColumn) -> str:
        """Transform date column names to dimension group names.

        Removes 'Date' or 'date' suffix and converts to snake_case.
        Handles nested fields by processing each part separately.
        Only converts what can be reliably converted (CamelCase and nested fields).

        Examples:
            DeliveryStartDate -> delivery_start (CamelCase conversion)
            deliverystartdate -> deliverystartdate (lowercase - keep as-is)
            format.period.EndDate -> format__period__end (nested fields)
        """
        from dbt2lookml.utils import camel_to_snake

        # Use original name to preserve CamelCase for proper conversion
        column_name = column.original_name or column.name

        # Handle nested fields first
        if '.' in column_name:
            parts = column_name.split('.')
            snake_parts = []
            for i, part in enumerate(parts):
                # Only remove date suffix from the last part (actual column name)
                if i == len(parts) - 1:  # Last part
                    if part.endswith('Date'):
                        part = part[:-4]  # Remove 'Date'
                    elif part.lower().endswith('date') and not part.endswith('_date'):
                        part = part[:-4]  # Remove 'date' but not '_date'

                # Apply the same realistic conversion logic to each part
                if part.islower() and '_' not in part:
                    # Pure lowercase - keep as-is
                    snake_parts.append(part)
                else:
                    # CamelCase or snake_case - convert
                    snake_parts.append(camel_to_snake(part))
            result = '__'.join(snake_parts)
        else:
            # Single field - remove date suffix first, then segment and convert
            # Special case: if column name is exactly "Date", don't remove the suffix
            if column_name == 'Date':
                result = 'date'  # Keep as 'date' for dimension_group name
            elif column_name == 'date':
                result = 'date'  # Keep as 'date' for dimension_group name
            elif column_name.endswith('Date'):
                base_name = column_name[:-4]  # Remove 'Date'
                # Clean up trailing underscores from base_name first
                base_name = base_name.rstrip('_')
                
                # Only convert what we can reliably handle
                if base_name.islower() and '_' not in base_name:
                    # Pure lowercase concatenated words - keep as-is
                    result = base_name
                else:
                    # CamelCase or snake_case - can convert reliably
                    result = camel_to_snake(base_name)
            elif column_name.lower().endswith('date'):
                base_name = column_name[:-4]  # Remove 'date' or '_date'
                # Clean up trailing underscores from base_name first
                base_name = base_name.rstrip('_')
                
                # Only convert what we can reliably handle
                if base_name.islower() and '_' not in base_name:
                    # Pure lowercase concatenated words - keep as-is
                    result = base_name
                else:
                    # CamelCase or snake_case - can convert reliably
                    result = camel_to_snake(base_name)
            else:
                base_name = column_name
                # Only convert what we can reliably handle
                if base_name.islower() and '_' not in base_name:
                    # Pure lowercase concatenated words - keep as-is
                    result = base_name
                else:
                    # CamelCase or snake_case - can convert reliably
                    result = camel_to_snake(base_name)

        # Clean up any trailing underscores
        result = result.rstrip('_')
        return result

    def _get_dimension_group_generated_names(self, column_name: str, looker_type: str) -> List[str]:
        """Get all dimension names that would be generated by a dimension group.
        Args:
            column_name: Base name of the column (with _date suffix removed)
            looker_type: Type of dimension group (date or time)
        Returns:
            List of dimension names that would be generated
        """
        if looker_type == "date":
            timeframes = self._custom_timeframes.get('date', LookerDateTimeframes.values())
        elif looker_type == "time":
            timeframes = self._custom_timeframes.get('time', LookerTimeTimeframes.values())
        else:
            return []
        return [f"{column_name}_{timeframe}" for timeframe in timeframes]

    def _create_group_label(self, parts: list[str]) -> str:
        """Create a human-readable group label from nested field parts.

        Args:
            parts: List of field name parts (e.g., ['classification', 'assortment'])

        Returns:
            Formatted group label (e.g., 'Classification Assortment')
        """
        # Convert each part to title case, handling common patterns
        formatted_parts = []
        for part in parts:
            from dbt2lookml.utils import camel_to_snake

            snake_case = camel_to_snake(part)
            title_case = snake_case.replace('_', ' ').capitalize()
            formatted_parts.append(title_case)

        return ' '.join(formatted_parts)

    def _create_item_label(self, item: str) -> str:
        from dbt2lookml.utils import camel_to_snake

        snake_case = camel_to_snake(item)
        return snake_case.replace('_', ' ').capitalize()

    def _create_single_array_dimension(self, column: DbtModelColumn) -> Dict[str, Any]:
        """Create a dimension for a simple array type.
        Args:
            column: Column to create dimension from
        Returns:
            Dictionary containing dimension definition
        """
        data_type = map_bigquery_to_looker(column.inner_types[0])
        return {
            "name": column.lookml_name,
            "type": data_type,
            "sql": column.lookml_name,
            "description": column.description or "",
        }

    def _is_single_type_array(self, column: DbtModelColumn) -> bool:
        """Check if column is a simple array type.
        Args:
            column: Column to check
        Returns:
            Whether column is a simple array type
        """
        return column.data_type == "ARRAY" and (len(column.inner_types) == 1 and " " not in column.inner_types[0])

    def _add_dimension_to_dimension_group(self, model: DbtModel, dimensions: List[Dict[str, Any]], table_format_sql: bool = True):
        """Add dimensions to dimension groups.
        Args:
            model: Model containing dimensions
            dimensions: List of dimensions to add
            table_format_sql: Whether to format SQL for table
        """
        for column in model.columns.values():
            if column.data_type == "DATE":
                _, _, dimension_group_dimensions = self.lookml_dimension_group(column, "date", table_format_sql, model)
                if dimension_group_dimensions:
                    dimensions.extend(dimension_group_dimensions)

    def lookml_dimensions_from_model(
        self,
        model: DbtModel,
        include_names: Optional[List[str]] = None,
        exclude_names: Optional[List[str]] = None,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """Generate dimensions from model.
        Args:
            model: Model to generate dimensions from
            include_names: List of names to include
            exclude_names: List of names to exclude
        Returns:
            Tuple containing dimensions and nested dimensions
        """
        if exclude_names is None:
            exclude_names = []
        dimensions: List[Dict[str, Any]] = []
        table_format_sql = True
        nested_dimensions: List[Dict[str, Any]] = []
        # First add ISO date dimensions for main view only if flag is enabled
        if not include_names:
            if self._include_iso_fields:  # Only for main view and if ISO fields are enabled
                self._add_dimension_to_dimension_group(model, dimensions, table_format_sql)

        # For main view, add nested array dimensions and group nested classification fields
        if not include_names:
            # Build hierarchy map to identify nested arrays
            def build_hierarchy_map(columns):
                """Build a map of parent -> children relationships based on dot notation."""
                hierarchy = {}
                for col in columns.values():
                    parts = col.name.split('.')
                    for i in range(len(parts)):
                        parent_path = '.'.join(parts[:i+1])
                        if parent_path not in hierarchy:
                            hierarchy[parent_path] = {
                                'children': set(),
                                'is_array': col.data_type and 'ARRAY' in str(col.data_type).upper() if i == len(parts) - 1 else False,
                                'column': col if i == len(parts) - 1 else None
                            }
                        
                        # Add child relationships
                        if i < len(parts) - 1:
                            child_path = '.'.join(parts[:i+2])
                            hierarchy[parent_path]['children'].add(child_path)
                return hierarchy
            
            hierarchy = build_hierarchy_map(model.columns)
            
            # Find top-level arrays that contain other arrays and create nested array dimensions
            for col in model.columns.values():
                if (col.data_type and str(col.data_type).upper().startswith('ARRAY') and 
                    '.' not in col.name):  # Only top-level arrays (not STRUCTs containing arrays)
                    # Check if this array contains other arrays (not just STRUCTs containing arrays)
                    array_path = col.name
                    if array_path in hierarchy:
                        for child_path in hierarchy[array_path]['children']:
                            child_col = hierarchy[child_path].get('column')
                            if (child_col and child_col.data_type and 
                                str(child_col.data_type).upper().startswith('ARRAY') and
                                len(hierarchy[child_path]['children']) > 0):
                                # Create nested array dimension only for actual nested arrays
                                nested_array_name = f"{col.name}__{child_path.split('.')[-1]}"
                                nested_array_dimension = {
                                    'name': nested_array_name,
                                    'type': 'string', 
                                    'hidden': 'yes',
                                    'sql': f"${{TABLE}}.{child_path}"
                                }
                                nested_dimensions.append(nested_array_dimension)
            
            processed_columns = set()
            for column in model.columns.values():
                if column.name in processed_columns:
                    continue

                # Process regular column
                # Convert column name to dimension name format for exclusion check
                dimension_name = column.name.replace('.', '__')
                if column.name in exclude_names or dimension_name in exclude_names or column.data_type == "DATETIME":
                    processed_columns.add(column.name)
                    continue
                # Skip date dimensions since we handled them above
                if column.data_type == "DATE":
                    processed_columns.add(column.name)
                    continue
                if column.data_type is None:
                    processed_columns.add(column.name)
                    continue

                # If this is a classification struct, skip it and add its nested fields instead
                if column.name == 'classification' and "STRUCT" in f"{column.data_type}":
                    classification_fields = []
                    for nested_col in model.columns.values():
                        # Convert nested column name to dimension name format for exclusion check
                        nested_dimension_name = nested_col.name.replace('.', '__')
                        if (
                            nested_col.name.startswith('classification.')
                            and nested_col.name not in processed_columns
                            and nested_col.name not in exclude_names
                            and nested_dimension_name not in exclude_names
                        ):
                            nested_column_name = get_column_name(nested_col, table_format_sql)
                            nested_dimension = self._create_dimension(nested_col, nested_column_name, include_names=include_names)
                            if nested_dimension is not None:
                                classification_fields.append(nested_dimension)
                                processed_columns.add(nested_col.name)
                    # Add classification fields in sorted order
                    classification_fields.sort(key=lambda d: d.get('name', ''))
                    dimensions.extend(classification_fields)
                    processed_columns.add(column.name)
                else:
                    # Process regular column
                    column_name = get_column_name(column, table_format_sql)
                    dimension = self._create_dimension(column, column_name, include_names=include_names)
                    if dimension is not None:
                        dimensions.append(dimension)
                    processed_columns.add(column.name)
        else:
            # For nested views, use original logic
            for column in model.columns.values():
                table_format_sql = True  # Always use ${TABLE} format for nested views
                # For nested views, only include fields that are children of the parent
                # or the parent itself if it's a simple array
                parent = include_names[0] if include_names else None
                if column.name == parent:
                    # Keep parent field only if it's a simple array (e.g. ARRAY<INT64>)
                    if self._is_single_type_array(column):
                        dimensions.append(self._create_single_array_dimension(column))
                    # Skip column equal to parent
                    continue
                elif not column.name.startswith(f"{parent}."):
                    continue
                # Convert column name to dimension name format for exclusion check
                dimension_name = column.name.replace('.', '__')
                if column.name in exclude_names or dimension_name in exclude_names or column.data_type == "DATETIME":
                    continue
                # Skip date dimensions since we handled them above
                if column.data_type == "DATE":
                    continue
                if column.data_type is None:
                    continue
                column_name = get_column_name(column, table_format_sql)
                dimension = self._create_dimension(column, column_name, include_names=include_names)
                if dimension is not None:
                    dimensions.append(dimension)
        return dimensions, nested_dimensions

    def lookml_dimension_groups_from_model(
        self,
        model: DbtModel,
        include_names: Optional[List[str]] = None,
        exclude_names: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """Generate dimension groups from model.
        Args:
            model: Model to generate dimension groups from
            include_names: List of names to include
            exclude_names: List of names to exclude
        Returns:
            Dictionary containing dimension groups and dimension group sets
        """
        if exclude_names is None:
            exclude_names = []
        dimension_groups = []
        dimension_group_sets = []
        table_format_sql = not include_names
        for column in model.columns.values():
            if include_names and column.name not in include_names:
                continue
            # Convert column name to dimension name format for exclusion check
            dimension_name = column.name.replace('.', '__')
            if exclude_names and (column.name in exclude_names or dimension_name in exclude_names):
                continue
            looker_type = self._get_looker_type(column)
            if looker_type in ("time", "date"):
                dimension_group, dimension_group_set, dimensions = self.lookml_dimension_group(
                    column=column,
                    looker_type=looker_type,
                    table_format_sql=table_format_sql,
                    model=model,
                )
                if dimension_group:
                    dimension_groups.append(dimension_group)
                if dimension_group_set:
                    dimension_group_sets.append(dimension_group_set)
        return {
            "dimension_groups": dimension_groups or None,
            "dimension_group_sets": dimension_group_sets or None,
        }
